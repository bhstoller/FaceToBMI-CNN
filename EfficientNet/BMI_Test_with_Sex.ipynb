{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae2ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac75251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetBMI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_v2_s(weights=weights)\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features + 1),\n",
    "            nn.Linear(num_features + 1, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_sex):\n",
    "        x = self.backbone(x_img)\n",
    "        x = torch.cat((x, x_sex.unsqueeze(1)), dim=1)\n",
    "        return self.fc(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc93d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMIDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.valid_indices = [\n",
    "            idx for idx in range(len(self.data))\n",
    "            if os.path.exists(os.path.join(self.img_dir, self.data.loc[idx, \"name\"].strip()))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.valid_indices[idx]\n",
    "        row = self.data.loc[real_idx]\n",
    "        img_path = os.path.join(self.img_dir, row[\"name\"].strip())\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        bmi_z = row[\"bmi_z\"]\n",
    "        sex = row[\"sex\"]\n",
    "        return image, torch.tensor(bmi_z, dtype=torch.float32), torch.tensor(sex, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576f70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare test data\n",
    "test_df = pd.read_csv(\"/Users/yuhsuanko/Desktop/UChicago/UChicago_Q3/ML_II/Final_Project/BMI/Data/data.csv\")\n",
    "test_df = test_df[test_df[\"is_training\"] == 0].reset_index(drop=True)\n",
    "if \"sex\" not in test_df.columns and \"gender\" in test_df.columns:\n",
    "    test_df[\"sex\"] = test_df[\"gender\"].map({\"Male\": 0, \"Female\": 1})\n",
    "mean_bmi = 32.53\n",
    "std_bmi = 8.04\n",
    "test_df[\"bmi_z\"] = (test_df[\"bmi\"] - mean_bmi) / std_bmi\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = BMIDataset(test_df, img_dir=\"/Users/yuhsuanko/Desktop/UChicago/UChicago_Q3/ML_II/Final_Project/BMI/Data/Images\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ded2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and evaluate\n",
    "model = EfficientNetBMI()\n",
    "model.load_state_dict(torch.load(\"/Users/yuhsuanko/Desktop/UChicago/UChicago_Q3/ML_II/Final_Project/best_bmi_model.pt\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets, sexes in test_loader:\n",
    "        outputs = model(images, sexes)\n",
    "        preds = outputs.numpy()\n",
    "        true = targets.numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(true)\n",
    "\n",
    "# Inverse transform predictions\n",
    "preds_bmi = np.array(all_preds) * std_bmi + mean_bmi\n",
    "targets_bmi = np.array(all_targets) * std_bmi + mean_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8894c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.57\n",
      "RMSE: 7.77\n",
      "R²: 0.2892\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "mae = mean_absolute_error(targets_bmi, preds_bmi)\n",
    "rmse = mean_squared_error(targets_bmi, preds_bmi) ** 0.5\n",
    "r2 = r2_score(targets_bmi, preds_bmi)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsp-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
