{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fbe7fd",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "id": "763e3ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:25.982625Z",
     "start_time": "2025-05-29T21:01:01.892161Z"
    }
   },
   "source": [
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c79cd948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:26.039185Z",
     "start_time": "2025-05-29T21:01:25.988572Z"
    }
   },
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} as device.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps as device.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "1cfd1ac7",
   "metadata": {},
   "source": [
    "# Function Library"
   ]
  },
  {
   "cell_type": "code",
   "id": "b1c57da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:26.116611Z",
     "start_time": "2025-05-29T21:01:26.112309Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, val_loader, y_scaler, epochs=5):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for imgs, _, idxs in tqdm(train_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = torch.tensor([bmis_scaled[idx] for idx in idxs], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _, idxs in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = torch.tensor(bmis_scaled[idxs], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                preds = model(imgs)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_preds_real = y_scaler.inverse_transform(np.array(val_preds).reshape(-1, 1)).ravel()\n",
    "        val_labels_real = y_scaler.inverse_transform(np.array(val_labels).reshape(-1, 1)).ravel()\n",
    "\n",
    "        mae = mean_absolute_error(val_labels_real, val_preds_real)\n",
    "        r2 = r2_score(val_labels_real, val_preds_real)\n",
    "        r, _ = pearsonr(val_labels_real, val_preds_real)\n",
    "\n",
    "        print(f\"Val MAE: {mae:.2f} | Val RÂ²: {r2:.3f} | Pearson r: {r:.3f}\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(mae)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a6e99368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:26.124390Z",
     "start_time": "2025-05-29T21:01:26.121751Z"
    }
   },
   "source": [
    "class ViTBMIRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.vit.config.hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(pixel_values=x)\n",
    "        cls_token = outputs.last_hidden_state[:, 0]\n",
    "        return self.regressor(cls_token)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "48141d76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:26.132495Z",
     "start_time": "2025-05-29T21:01:26.129285Z"
    }
   },
   "source": [
    "class BMIDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Remove any rows without image files\n",
    "        self.df['full_path'] = self.df['name'].apply(lambda x: os.path.join(image_dir, x))\n",
    "        self.df = self.df[self.df['full_path'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['full_path']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = row['bmi']\n",
    "        return img, label, idx "
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "e96c9540",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "441bdaf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:26.174131Z",
     "start_time": "2025-05-29T21:01:26.137247Z"
    }
   },
   "source": [
    "# Basic transform\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # Normalized to [-1, 1]\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "dataset = BMIDataset(\n",
    "    csv_path='../Data/data.csv',\n",
    "    image_dir='../Data/Images',\n",
    "    transform=img_transform\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "19a23399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:07:02.861798Z",
     "start_time": "2025-05-29T21:07:02.841271Z"
    }
   },
   "source": [
    "# Load BMI column and scale\n",
    "df = pd.read_csv('../Data/data.csv')\n",
    "bmis = df['bmi'].values\n",
    "y_scaler = StandardScaler()\n",
    "bmis_scaled = y_scaler.fit_transform(bmis.reshape(-1, 1)).ravel()\n",
    "\n",
    "joblib.dump(y_scaler, \"y_scaler.pkl\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e294b721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:23:30.852408Z",
     "start_time": "2025-05-29T21:23:30.748490Z"
    }
   },
   "source": [
    "extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std)\n",
    "])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyler/CodeStuff/Classes/uchicago/ml_ii/venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "4edcbe62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:23:31.607617Z",
     "start_time": "2025-05-29T21:23:31.083878Z"
    }
   },
   "source": [
    "model = ViTBMIRegressor().to(device)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "f06c9fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:23:31.616407Z",
     "start_time": "2025-05-29T21:23:31.612271Z"
    }
   },
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Optional learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "06cda08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:46:11.426891Z",
     "start_time": "2025-05-29T21:23:33.106847Z"
    }
   },
   "source": [
    "train_model(model, train_loader, val_loader, y_scaler, epochs=10)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [02:28<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train Loss = 0.9870\n",
      "Val MAE: 6.22 | Val RÂ²: -0.003 | Pearson r: -0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [01:58<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train Loss = 0.9602\n",
      "Val MAE: 6.22 | Val RÂ²: -0.006 | Pearson r: -0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [01:53<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train Loss = 0.9357\n",
      "Val MAE: 6.22 | Val RÂ²: -0.011 | Pearson r: -0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [01:31<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train Loss = 0.8969\n",
      "Val MAE: 6.26 | Val RÂ²: -0.024 | Pearson r: -0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [01:36<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Train Loss = 0.8195\n",
      "Val MAE: 6.26 | Val RÂ²: -0.050 | Pearson r: -0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [01:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train Loss = 0.6986\n",
      "Val MAE: 6.43 | Val RÂ²: -0.104 | Pearson r: -0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [02:05<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train Loss = 0.5187\n",
      "Val MAE: 6.62 | Val RÂ²: -0.159 | Pearson r: -0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [02:31<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train Loss = 0.4100\n",
      "Val MAE: 6.77 | Val RÂ²: -0.222 | Pearson r: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [02:24<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train Loss = 0.3227\n",
      "Val MAE: 7.02 | Val RÂ²: -0.291 | Pearson r: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 100/100 [02:29<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train Loss = 0.2598\n",
      "Val MAE: 6.97 | Val RÂ²: -0.301 | Pearson r: 0.005\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "6cd4c2db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:46:12.229511Z",
     "start_time": "2025-05-29T21:46:11.467682Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), \"vit_model_final.pt\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "501993b669d3984"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
