{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fbe7fd",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "763e3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import ViTFeatureExtractor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79cd948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu as device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} as device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd1ac7",
   "metadata": {},
   "source": [
    "# Function Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c57da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, y_scaler, epochs=5):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for imgs, _, idxs in tqdm(train_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = torch.tensor([bmis_scaled[idx] for idx in idxs], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, _, idxs in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = torch.tensor(bmis_scaled[idxs], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "                preds = model(imgs)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_preds_real = y_scaler.inverse_transform(np.array(val_preds).reshape(-1, 1)).ravel()\n",
    "        val_labels_real = y_scaler.inverse_transform(np.array(val_labels).reshape(-1, 1)).ravel()\n",
    "\n",
    "        mae = mean_absolute_error(val_labels_real, val_preds_real)\n",
    "        r2 = r2_score(val_labels_real, val_preds_real)\n",
    "        r, _ = pearsonr(val_labels_real, val_preds_real)\n",
    "\n",
    "        print(f\"Val MAE: {mae:.2f} | Val R²: {r2:.3f} | Pearson r: {r:.3f}\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e99368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTBMIRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.vit.config.hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(pixel_values=x)\n",
    "        cls_token = outputs.last_hidden_state[:, 0]\n",
    "        return self.regressor(cls_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48141d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMIDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Remove any rows without image files\n",
    "        self.df['full_path'] = self.df['name'].apply(lambda x: os.path.join(image_dir, x))\n",
    "        self.df = self.df[self.df['full_path'].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['full_path']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = row['bmi']\n",
    "        return img, label, idx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c9540",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "441bdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic transform\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # Normalized to [-1, 1]\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "dataset = BMIDataset(\n",
    "    csv_path='../data/BMI/cleaned_data.csv',\n",
    "    image_dir='../data/BMI/Images',\n",
    "    transform=img_transform\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19a23399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BMI column and scale\n",
    "df = pd.read_csv('../data/BMI/cleaned_data.csv')\n",
    "bmis = df['bmi'].values\n",
    "y_scaler = StandardScaler()\n",
    "bmis_scaled = y_scaler.fit_transform(bmis.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4edcbe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51a64a484654ee6a720b7c37901cd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9508113f5bb4df58ac90d5f72f2a8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ViTBMIRegressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06c9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Optional learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06cda08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:18<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train Loss = 0.6709\n",
      "Val MAE: 4.65 | Val R²: 0.388 | Pearson r: 0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:20<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train Loss = 0.4814\n",
      "Val MAE: 4.45 | Val R²: 0.442 | Pearson r: 0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:59<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train Loss = 0.3730\n",
      "Val MAE: 4.40 | Val R²: 0.460 | Pearson r: 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:08<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train Loss = 0.2885\n",
      "Val MAE: 4.39 | Val R²: 0.465 | Pearson r: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:55<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Train Loss = 0.2314\n",
      "Val MAE: 4.45 | Val R²: 0.453 | Pearson r: 0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:51<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train Loss = 0.1781\n",
      "Val MAE: 4.40 | Val R²: 0.462 | Pearson r: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:54<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train Loss = 0.1474\n",
      "Val MAE: 4.41 | Val R²: 0.453 | Pearson r: 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:54<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train Loss = 0.1155\n",
      "Val MAE: 4.44 | Val R²: 0.470 | Pearson r: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train Loss = 0.1051\n",
      "Val MAE: 4.53 | Val R²: 0.454 | Pearson r: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:48<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train Loss = 0.0955\n",
      "Val MAE: 4.41 | Val R²: 0.461 | Pearson r: 0.685\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, y_scaler, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cd4c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vit_model_final.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
